{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5683932a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '№' (U+2116) (3316271523.py, line 138)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [109]\u001b[0;36m\u001b[0m\n\u001b[0;31m    student№s.describe()\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '№' (U+2116)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', sep=',', index_col=0,\n",
    "                       dtype = {'row_id': 'int64', 'timestamp': 'int64', 'user_id': 'int32', 'content_id': 'int16', \n",
    "                                'content_type_id': 'int8', 'task_container_id': 'int16', 'user_answer': 'int8', \n",
    "                                'answered_correctly': 'int8', 'prior_question_elapsed_time': 'float32', \n",
    "                                'prior_question_had_explanation': 'boolean'\n",
    "                               }\n",
    "                      )\n",
    "\n",
    "train.head()\n",
    "for i in range(train.shape[0]):\n",
    "    if pd.isna(train['prior_question_had_explanation'][i]) == True:\n",
    "        train['prior_question_had_explanation'][i] = False\n",
    "train['prior_question_had_explanation'] = train['prior_question_had_explanation'].astype('int8')\n",
    "\n",
    "train.info()\n",
    "unique_list = []\n",
    "for col in train.columns:\n",
    "    item = (col, train[col].nunique(), train[col].dtype)\n",
    "    unique_list.append(item)\n",
    "unique_counts = pd.DataFrame(unique_list,\n",
    "                             columns=['Column_Name', 'Num_Unique', 'Type']\n",
    "                            ).sort_values(by='Num_Unique',  ignore_index=True)\n",
    "display(unique_counts)\n",
    "\n",
    "\n",
    "# 0-вопросы, 1-лекции\n",
    "train['content_type_id'].value_counts(normalize=True) \n",
    "train['content_type_id'].value_counts()[0] \n",
    "train['content_type_id'].value_counts()[1] \n",
    "\n",
    "#Соотношение правильных и неправильных\n",
    "train[train['answered_correctly'] != -1]['answered_correctly'].value_counts(normalize=True) \n",
    "train[train['answered_correctly'] != -1]['answered_correctly'].value_counts()[1] \n",
    "train[train['answered_correctly'] != -1]['answered_correctly'].value_counts()[0]\n",
    "train[train['answered_correctly'] != -1]['answered_correctly'].mean()\n",
    "# 66% составляют правильные ответы, 34% - неправильные\n",
    "# всего 65244627 правильных ответов и 34026673 неправильных ответов\n",
    "# 0.657 - средний балл студента\n",
    "\n",
    "#Среднее время на решение\n",
    "train['prior_question_elapsed_time'].mean()\n",
    "# Cреднее число отвеченных вопросов: 252.17\n",
    "# Среднее кол-во правильных ответов: 165.74\n",
    "# Среднее число просмотренных лекций: 4.97\n",
    "# Среднее число виденных объяснений: 227.82\n",
    "# Среднее время, затрачиваемое на вопрос: 13005\n",
    "pd.DataFrame({'timestamp': train[train['answered_correctly'] != -1]['timestamp'].groupby(train['answered_correctly']).mean(),\n",
    "              'prior_questions_time': train[train['answered_correctly'] != -1]['prior_question_elapsed_time'].groupby(train['answered_correctly']).mean(),\n",
    "              'had_explanation': train[train['answered_correctly'] != -1]['prior_question_had_explanation'].groupby(train['answered_correctly']).sum()\n",
    "             }\n",
    "            )\n",
    "\n",
    "# Можно сделать следующие выводы:\n",
    "# - чем ближе к началу сессии вопрос, тем менее успешно его проходят студенты \n",
    "# (т.е. успешность коррелирует со временем, проведенным на платформе)\n",
    "# - студенты, тратящие меньше времени на решение, чаще отвечают правильно\n",
    "# - если студент видел объяснение предыдущий задачи, вероятность правильного ответа удваивается\n",
    "\n",
    "\n",
    "#Основные выводы по разделу 1:\n",
    "#Всего в данных присутствует информация об активности 393656 студентов.\n",
    "#На платформе 13523 вопросов (объединенных в 10000 блоков) и 418 лекций по 7 темам.\n",
    "#В среднем на ответ на вопрос у студентов уходит\n",
    "#98% активновти студентов приходится на ответы на вопросы, только 2% татится на просмотр лекций.\n",
    "#66% составляют правильные ответы, 34% - неправильные.\n",
    "#0.657 - средний балл студента\n",
    "#Cреднее число отвеченных вопросов: 252.17\n",
    "#Среднее кол-во правильных ответов: 165.74\n",
    "#Среднее число просмотренных лекций: 4.97\n",
    "#Среднее число виденных объяснений: 227.82\n",
    "#Среднее время, затрачиваемое на вопрос: 13005\n",
    "#Cреднее время на решение вопроса 13005 милисекунд (= 13 секунд)\n",
    "#Чем ближе к началу сессии вопрос, тем менее успешно его проходят студенты (т.е. успешность коррелирует со временем, проведенным на платформе)\n",
    "#Студенты в среднем тратят меньше времени на правильный ответ, чем на неправильный (возможно, меньше сомневаются)\n",
    "#Если студент видел объяснение предыдущий задачи, он в 2 раза чаще отвечает правильно, чем неправильно\n",
    "\n",
    "#Новый DF\n",
    "sudents_list = list(train['user_id'].unique())\n",
    "users_q = len(sudents_list)\n",
    "#Сокращении до 500\n",
    "sudents_list = sudents_list[:500]\n",
    "#Время работы каждого студента\n",
    "time = []\n",
    "for student in sudents_list:\n",
    "    t = train[train['user_id'] == student]['timestamp'].max()\n",
    "    time.append(t)\n",
    "#сколько всего ответил на вопросы\n",
    "ques_quant = []\n",
    "for student in sudents_list:\n",
    "    q = train[(train['user_id'] == student) & (train['content_type_id'] == 0)]['content_type_id'].count()\n",
    "    ques_quant.append(q)\n",
    "    \n",
    "#Средний балл студента\n",
    "av_grade = []\n",
    "for student in sudents_list:\n",
    "    g = train[(train['user_id'] == student) & (train['answered_correctly'] != -1)]['answered_correctly'].mean()\n",
    "    av_grade.append(g)\n",
    "#Просмотренные лекции\n",
    "lec_watched = []\n",
    "for student in sudents_list:\n",
    "    l = train[train['user_id'] == student]['content_type_id'].sum()\n",
    "    lec_watched.append(l)\n",
    "    \n",
    "#Кол-ва объяснений на вопросы\n",
    "expl_watched = []\n",
    "for student in sudents_list:\n",
    "    e = train[train['user_id'] == student]['prior_question_had_explanation'].sum()\n",
    "    expl_watched.append(e)\n",
    "    \n",
    "#Среднее время на вопрос\n",
    "ques_time = []\n",
    "for student in sudents_list:\n",
    "    qt = train[(train['user_id'] == student)]['prior_question_elapsed_time'].mean()\n",
    "    ques_time.append(qt)\n",
    "    \n",
    "#Первые 500 студентов  \n",
    "students = pd.DataFrame({'user_id': sudents_list,\n",
    "                        'time': time,\n",
    "                        'ques_quant': ques_quant,\n",
    "                        'av_grade': av_grade,\n",
    "                        'lec_watched': lec_watched,\n",
    "                        'expl_watched': expl_watched,\n",
    "                         'ques_time': ques_time\n",
    "                       }\n",
    "                      )\n",
    "students = students.astype({'user_id': 'int32',\n",
    "                            'time': 'int64',\n",
    "                            'ques_quant': 'int16', \n",
    "                            'av_grade': 'float32',\n",
    "                            'lec_watched': 'int16',\n",
    "                            'expl_watched': 'int16',\n",
    "                            'ques_time': 'float32'\n",
    "                           })\n",
    "\n",
    "students.head()\n",
    "#Сравнение выборки с оригиналом\n",
    "students.describe()\n",
    "\n",
    "# Мы видим, что наша выборка средними значениями отличается от общего датасета:\n",
    "# средняя успеваемость у нашей группы ниже, чем у полного набора данных, \n",
    "# при этом среднее число просмотренных лекций и объяснений выше\n",
    "# (за счет относительно небольшого кол-ва очень активно учащихся студентов\n",
    "# это видно из смещения кол-ва отвеченных вопросов, просмотренных лекций и объяснений в верхний квартиль\n",
    "# и высокой дисперсии)\n",
    "# Однако все значения укладываются в среднеквадратическое отклонение, \n",
    "# поэтому можем считать их несущественными для результатов анализа\n",
    "\n",
    "\n",
    "#Гистограмма распределения средниц оценок\n",
    "\n",
    "students['av_grade'].hist(bins=20)\n",
    "\n",
    "students['av_grade'].median()\n",
    "\n",
    "\n",
    "students[students['time'] < 3000000].plot.scatter(x='av_grade', y='time')\n",
    "\n",
    "# Из графика неочевидно, что с ростом времени, затраченного на платформе, растет процент правильных ответов у студентов\n",
    "# Можем сделать 2 предположения:\n",
    "# - либо время, проведенное на платформе не имеет значимого влияния на успеваемость\n",
    "# - либо для эффекта нужно затрачивать время сильно больше, чем это делает большинство студентов\n",
    "# (возможно студенты слишком рано бросают занятия)\n",
    "\n",
    "\n",
    "#Когда студент бросает занятия\n",
    "\n",
    "students[students['time'] < 3000000].hist(column=['time'])\n",
    "\n",
    "# Мы видим, что после 1000000 милисекунд (=17 минут) 1/5 часть студентов не продолжает обучения, \n",
    "# после 2500000 милисекунд (=42 минуты) учебу бросает уже треть\n",
    "# Получается, то, что мы изначально сочли выбросами - это наша основная рабочая выборка, которую надо исследовать,\n",
    "# чтобы понять влияние факторов на успеваемость. \n",
    "\n",
    "# строка для проверки данных отсечения\n",
    "students[students['time'] < 2500000].shape\n",
    "#Построим диаграмму рассеяния для студентов, не бросивших учебу в течение 1го часа.\n",
    "students[students['time'] > 3000000].plot.scatter(x='av_grade', y='time')\n",
    "\n",
    "# Здесь уже становится видна тенденция роста успеваемости с течением веремени\n",
    "#разбиение студентов по временным группам:\n",
    "# - Добавим столбец с временной группировкой\n",
    "# - Построим диаграмму размаха\n",
    "def time_convert(e):\n",
    "    if e < students['time'].quantile(0.1): return 0\n",
    "    elif e < students['time'].quantile(0.2): return 1\n",
    "    elif e < students['time'].quantile(0.3): return 2\n",
    "    elif e < students['time'].quantile(0.4): return 3\n",
    "    elif e < students['time'].quantile(0.5): return 4\n",
    "    elif e < students['time'].quantile(0.6): return 5\n",
    "    elif e < students['time'].quantile(0.7): return 6\n",
    "    elif e < students['time'].quantile(0.8): return 7\n",
    "    elif e < students['time'].quantile(0.9): return 8\n",
    "    else: return 9\n",
    "    \n",
    "students['time_group'] = students['time'].apply(time_convert)\n",
    "\n",
    "students.boxplot(column=['av_grade'], by=['time_group'])\n",
    "\n",
    "# Первый эффект от занятий становится виден, если студент не бросает заниматься\n",
    "# При этом, если студент потратил на занятия не менее 55 часов, его оценка становится устойчиво выше средней\n",
    "# и продолжает расти со временем.\n",
    "# Однако, если курс не пройден за ~ полгода, оценка становится нестабильной\n",
    "# Т.е. стоит не только стимулировать студентов не бросать занятия после первого подхода,\n",
    "# но и закончить курс за первые полгода обучения.\n",
    "\n",
    "students['time'].quantile(0.7)/1000/60/60/8\n",
    "\n",
    "#зависимость правильных ответов от кол-ва сделанных заданий\n",
    "#Ограничим выборку студентами, не бросившими обучение сразу.\n",
    "\n",
    "students[(students['ques_quant'] < 1000) & (students['time'] > 3000000)].plot.scatter(x='av_grade', y='ques_quant', c='red')\n",
    "\n",
    "# чтобы убрать выбросы, ограничим данные сверху 1000\n",
    "# На графике довольно очевидна связь успеваемости с кол-вом отвеченных вопросов\n",
    "# Стоит провести группировку вопросов по кол-ву для дальнейшего анализа\n",
    "\n",
    "#группировка по количеству отвеченных вопросов\n",
    "def ques_convert(e):\n",
    "    if e < students['ques_quant'].quantile(0.1): return 0\n",
    "    elif e < students['ques_quant'].quantile(0.2): return 1\n",
    "    elif e < students['ques_quant'].quantile(0.3): return 2\n",
    "    elif e < students['ques_quant'].quantile(0.4): return 3\n",
    "    elif e < students['ques_quant'].quantile(0.5): return 4\n",
    "    elif e < students['ques_quant'].quantile(0.6): return 5\n",
    "    elif e < students['ques_quant'].quantile(0.7): return 6\n",
    "    elif e < students['ques_quant'].quantile(0.8): return 7\n",
    "    elif e < students['ques_quant'].quantile(0.9): return 8\n",
    "    else: return 9\n",
    "    \n",
    "students['q_group'] = students['ques_quant'].apply(ques_convert)\n",
    "\n",
    "\n",
    "students.boxplot(column=['av_grade'], by=['q_group'])\n",
    "\n",
    "# Мы видим странную просадку в 4м квартиле\n",
    "students['ques_quant'].quantile(0.4)\n",
    "# Можем предположить, что первые вопросы являются сильным демотиватором для учащегося.\n",
    "# Но если студент отвечает больше, чем на 34 вопроса, он постепенно начинает улучшать свои показатели\n",
    "# И дальше результаты только улучшаются\n",
    "# На гистограме видно, что 32 вопроса - порог отсечения для многих студентов из нашей выборки\n",
    "\n",
    "students[(students['ques_quant'] < students['ques_quant'].quantile(0.5))].hist(column=['ques_quant'])\n",
    "#зависимость правильных ответов от кол-ва виденных объяснений\n",
    "students[(students['expl_watched'] < 500)].plot.scatter(x='av_grade', y='expl_watched', c='yellow')\n",
    "#группировка по правильным ответам\n",
    "def expl_convert(e):\n",
    "    if e < students['expl_watched'].quantile(0.1): return 0\n",
    "    elif e < students['expl_watched'].quantile(0.2): return 1\n",
    "    elif e < students['expl_watched'].quantile(0.3): return 2\n",
    "    elif e < students['expl_watched'].quantile(0.4): return 3\n",
    "    elif e < students['expl_watched'].quantile(0.5): return 4\n",
    "    elif e < students['expl_watched'].quantile(0.6): return 5\n",
    "    elif e < students['expl_watched'].quantile(0.7): return 6\n",
    "    elif e < students['expl_watched'].quantile(0.8): return 7\n",
    "    elif e < students['expl_watched'].quantile(0.9): return 8\n",
    "    else: return 9\n",
    "    \n",
    "students['e_group'] = students['expl_watched'].apply(expl_convert)\n",
    "\n",
    "students['expl_watched'].quantile(0.5)\n",
    "\n",
    "\n",
    "# здесь мы видим, что 34 вопроса - порог отсечения для многих студентов\n",
    "students[(students['expl_watched'] < students['expl_watched'].quantile(0.8))].hist(column=['expl_watched'])\n",
    "\n",
    "\n",
    "students.boxplot(column=['av_grade'], by=['e_group'])\n",
    "\n",
    "# Видно четкий тренд на повышение оценки с ростом кол-ва просмотренных объяснений\n",
    "#зависимость правильных ответов от лекций\n",
    "students[students['lec_watched'] < 21].plot.scatter(x='av_grade', y='lec_watched', c='green')\n",
    "\n",
    "# Мы видим, что экстремальные выбросы можно убрать, ограничив число 21 лекцией\n",
    "\n",
    "students[students['lec_watched'] < 21].boxplot(column=['av_grade'], by=['lec_watched'])\n",
    "\n",
    "# Мы видим, что даже просмотр 1 леции повышает средний балл и значительно повышает минимальную оценку студента.\n",
    "# Максимальный эффект достигается при просмотре 4-11 лекций, после чего эффективность просмотров снижается\n",
    "\n",
    "\n",
    "\n",
    "#Основные выводы по разделу 2\n",
    "#Мы сделали выборку из общего объема данных по 500 студентам. С учетом проведенного анализа мы можем сделать следующие выводы:\n",
    "\n",
    "#Треть студентов бросает учебу, проведя на платформе менее 42 минут. За это время, вероятно, они не успевают почувствовать эффект, либо им просто что-то не нравится (недостаточно мотивации / слишком сложные вопросы / неудобный интерфейс и т.д.).\n",
    "\n",
    "#Если студент потратил на занятия не менее 55 часов, его оценка становится устойчиво выше средней и продолжает расти со временем.\n",
    "\n",
    "#Если курс не пройден за ~ полгода, оценка становится нестабильной. Т.е. стоит не только стимулировать студентов не бросать занятия после первого подхода, но и закончить курс за первые полгода обучения.\n",
    "\n",
    "#Анализ данных по кол-ву отвеченных вопросов подсказывает, что первые вопросы сильно демотивируют учащихся. Большая часть не преодолевает порог в 32 вопроса. Следует стимуляровать студентов к ответу хотя бы на первые 60 вопросов, чтобы добиться устойчивого улучшения результатов и мотивации к дальнейшему обучению.\n",
    "\n",
    "#С ростом кол-ва просмотренных объяснений устойчиво растет успеваемость студентов.\n",
    "\n",
    "#Если студент посмотрит более 4х лекций, его успеваемость значительно возрастет. При этом просмотр более 11 лекций по какой-то причине не улучшает ситуацию.\n",
    "\n",
    "#3. Добавим к исследованию данные из дополнительных файлов\n",
    "#Исследуем данные \"Вопросы\"\n",
    "#questions.csv\n",
    "\n",
    "#question_id: внешний ключ вопроса - соответствует content_id\n",
    "#bundle_id: код, по которому вопросы отдаются совместно\n",
    "#correct_answer: правильный ответ. Можно использовать для проверки правильности user_answer\n",
    "#part: номер раздела в тесте TOEIC\n",
    "#tags: кодировка типа вопроса, можно использовать для кластеризации вопросов\n",
    "\n",
    "\n",
    "questions = pd.read_csv('questions.csv', sep=',',\n",
    "                        dtype = {'question_id': 'int16', 'bundle_id': 'int16', 'correct_answer': 'int8',\n",
    "                                 'part': 'int8', 'tags': 'object'\n",
    "                               })\n",
    "questions.info()\n",
    "\n",
    "#уникальные значения для колонок\n",
    "\n",
    "unique_list_q = []\n",
    "for col in questions.columns:\n",
    "    item = (col, questions[col].nunique(), questions[col].dtype)\n",
    "    unique_list_q.append(item)\n",
    "unique_counts_q = pd.DataFrame(unique_list_q,\n",
    "                               columns=['Column_Name', 'Num_Unique', 'Type']\n",
    "                              ).sort_values(by='Num_Unique',  ignore_index=True)\n",
    "display(unique_counts_q)\n",
    "\n",
    "questions['question_id'].groupby(questions['bundle_id']).count().max()\n",
    "questions['part'].value_counts(normalize=True)\n",
    "questions['tags'].describe()\n",
    "\n",
    "# Часть вопросов объединены по bundle_id в блоки до 5 вопросов, хотя большинство представлены по одиночке\n",
    "# Задачи разделены по темам на 7 разделов, больше всего посвящено 5му разделу, 2, 3 и 4\n",
    "\n",
    "\n",
    "q_tags = set()\n",
    "for tag in questions['tags']:\n",
    "    try:\n",
    "        for t in tag.split():\n",
    "                q_tags.add(int(t))\n",
    "    except:\n",
    "        q_tags.add(int(t))\n",
    "len(q_tags)\n",
    "\n",
    "# Можно провести доп исследование вопросов, используя кластеризацию по 188 доп.признакам 'tags'\n",
    "\n",
    "\n",
    "#Таблица с ID из train\n",
    "tmp_df = train.loc[(train.content_type_id == 0), ['content_id', 'answered_correctly']]\n",
    "\n",
    "q_list = list(tmp_df['content_id'].unique())\n",
    "len(q_list)\n",
    "\n",
    "# Всего 13523 уникальных вопросов. Мы берем этот список из файла Train, чтобы иметь правильный порядок данных\n",
    "\n",
    "q_quant = []\n",
    "correct_quant = []\n",
    "for q in q_list:\n",
    "    tmp = tmp_df[tmp_df['content_id'] == q]['answered_correctly'].count()\n",
    "    tmp1 = tmp_df[tmp_df['content_id'] == q]['answered_correctly'].sum()\n",
    "    q_quant.append(tmp)\n",
    "    correct_quant.append(tmp1)\n",
    "    \n",
    "    \n",
    "q_ex = pd.DataFrame({'question_id': q_list,\n",
    "                        'q_quant': q_quant,\n",
    "                        'correct_quant': correct_quant\n",
    "                       }\n",
    "                      )\n",
    "q_ex = q_ex.astype({'question_id': 'int16', 'q_quant': 'int32', 'correct_quant': 'int32'}\n",
    "                   \n",
    "                   \n",
    "questions = questions.drop('correct_answer', axis=1)\n",
    "questions = pd.merge(questions, q_ex, how='inner')\n",
    "                   \n",
    "                   \n",
    "questions['correct_percent'] = questions['correct_quant'] / questions['q_quant']\n",
    "questions.describe()\n",
    "                   \n",
    "                   \n",
    "questions\n",
    "                   \n",
    "                   \n",
    "#Дополнительные условия от которых может зависеть успеваемость\n",
    "questions.groupby('part').mean()['correct_percent'].sort_values()\n",
    "\n",
    "# По мере продвижения по разделам, видимо, сложность курса возрастает. \n",
    "# 5й раздел содержит максимальное число леций и заданий, однако средняя успеваемость студентов\n",
    "# для него самая низкая.\n",
    "                   \n",
    "#ЛЕКЦИИ\n",
    "                   \n",
    "lectures = pd.read_csv('lectures.csv', sep=',',\n",
    "                      dtype = {'lecture_id': 'int16', 'tag': 'int16', \n",
    "                               'part': 'int8', 'type_of': 'object'})\n",
    "lectures.info()\n",
    "                   \n",
    "                   \n",
    "#уникальные значения для колонок\n",
    "                   \n",
    "unique_list_lec = []\n",
    "for col in lectures.columns:\n",
    "    item = (col, lectures[col].nunique(), lectures[col].dtype)\n",
    "    unique_list_lec.append(item)\n",
    "unique_counts_lec = pd.DataFrame(unique_list_lec,\n",
    "                                 columns=['Column_Name', 'Num_Unique', 'Type']\n",
    "                                ).sort_values(by='Num_Unique',  ignore_index=True)\n",
    "display(unique_counts_lec)\n",
    "\n",
    "# Лекции разделены по темам на 7 разделов, больше всего лекций посвящено 5му разделу, затем 6, 2 и 1\n",
    "# С учетом данных по вопросам, можно прийти к заключению, что 5 раздел - самый насыщенный по материалу,\n",
    "# 6 и 1 - более теоретические, а 3 и 4 - более прикладные.\n",
    "# Леции бывают 4 типов: вступление, целеполагание, концептуальное изложение материала и решение задач.\n",
    "# Большинство лекций посвящены теории, немного меньше - решению задач. Доля остальных несущественна.\n",
    "# Есть 151 доп.тип лекций, по которым можно провести кластеризацию\n",
    "                   \n",
    "    \n",
    "                   \n",
    "lectures['part'].value_counts(normalize=True)\n",
    "lectures['type_of'].value_counts(normalize=True)\n",
    "lectures['tag'].value_counts().head()\n",
    "                   \n",
    "                   \n",
    "l_list = list(train[train['content_type_id'] == 1]['content_id'].unique())\n",
    "len(l_list)\n",
    "\n",
    "# Всего 415 уникальных лекций. Мы берем этот список из файла Train, чтобы иметь правильный порядок данных\n",
    "                   \n",
    "                   \n",
    "l_quant = []\n",
    "for l in l_list:\n",
    "    tmp_l = train[(train['content_id'] == l)]['content_id'].count()\n",
    "    l_quant.append(tmp_l)\n",
    "                   \n",
    "l_ex = pd.DataFrame({'lecture_id': l_list,\n",
    "                        'l_quant': l_quant\n",
    "                       }\n",
    "                      )\n",
    "l_ex = l_ex.astype({'lecture_id': 'int16', 'l_quant': 'int32'})\n",
    "                   \n",
    "                   \n",
    "lectures = pd.merge(lectures, l_ex, how='inner')\n",
    "display(lectures)\n",
    "                   \n",
    "                   \n",
    "lectures.sort_values(by=['l_quant'], ascending=False).head()\n",
    "        \n",
    "lectures.groupby('part').sum()['l_quant'].sort_values(ascending=False)\n",
    "                   \n",
    "for part in range(1, 8):\n",
    "    print(part, lectures.groupby('part').sum()['l_quant'].sort_values(ascending=False)[part]/lectures['part'].value_counts()[part])\n",
    "    \n",
    "# Наибольшее число просмотров имеет лекция из 7го раздела, \n",
    "# при этом самая высокая средневзвешенная популярность у лекций 2 раздела\n",
    "                   \n",
    "lectures.groupby('tag').sum()['l_quant'].sort_values(ascending=False).head()\n",
    "                   \n",
    "#новая таблица\n",
    "                   \n",
    "part_list = list(range(1, 8))\n",
    "ques_quant_p = [questions[questions.part == p]['question_id'].count() for p in range(1,8)]\n",
    "ans_quant_p = [questions[questions.part == p]['q_quant'].sum() for p in range(1,8)]\n",
    "right_quant_p = [questions[questions.part == p]['correct_quant'].sum() for p in range(1,8)]\n",
    "right_perc_p = [round(questions[questions.part == p]['correct_quant'].sum()/questions[questions.part == p]['q_quant'].sum(), 3) for p in range(1,8)]\n",
    "lec_quant_p = [lectures[lectures.part == p]['lecture_id'].count() for p in range(1,8)]\n",
    "lec_view_p = [lectures[lectures.part == p]['l_quant'].sum() for p in range(1,8)]\n",
    "lec_pop_p = [lectures[lectures.part == p]['l_quant'].sum()/lectures[lectures.part == p]['lecture_id'].count() for p in range(1,8)]\n",
    "norm_lec_pop_p = [round(pop / max(lec_pop_p), 3) for pop in lec_pop_p]\n",
    "part_df = pd.DataFrame({'part': part_list,\n",
    "                        'ques_quant_p': ques_quant_p,\n",
    "                        'ans_quant_p': ans_quant_p,\n",
    "                        'right_quant_p': right_quant_p,\n",
    "                        'right_perc_p': right_perc_p,\n",
    "                        'lec_quant_p': lec_quant_p,\n",
    "                        'lec_view_p': lec_view_p,\n",
    "                        'norm_lec_pop_p': norm_lec_pop_p\n",
    "                       }\n",
    "                      )\n",
    "part_df = part_df.astype({'part': 'int8',\n",
    "                        'ques_quant_p': 'int16',\n",
    "                        'ans_quant_p': 'int64',\n",
    "                        'right_quant_p': 'int64',\n",
    "                        'right_perc_p': 'float32',\n",
    "                        'lec_quant_p': 'int16',\n",
    "                        'lec_view_p': 'int32',\n",
    "                        'norm_lec_pop_p': 'float32'\n",
    "                       })\n",
    "                   \n",
    "part_df.sort_values(by='right_perc_p', ascending=False)\n",
    "    \n",
    "#Основные выводы по разделу 3:\n",
    "#Часть вопросов объединены по bundle_id в блоки до 5 вопросов, хотя большинство представлены по одиночке\n",
    "#Лекции бывают 4 типов: вступление, целеполагание, концептуальное изложение материала и решение задач.\n",
    "#Задачи и лекции разделены по темам на 7 разделов\n",
    "#Большинство лекций посвящены теории, немного меньше - решению задач. Доля остальных несущественна.\n",
    "#Наибольшее число просмотров имеет лекция из 7го раздела.\n",
    "#Самая высокая средневзвешенная популярность у лекций 2 раздела.\n",
    "#5 раздел - самый насыщенный по материалу, 6 и 1 - более теоретические, а 3 и 4 - более прикладные.\n",
    "#По мере продвижения по разделам, видимо, сложность курса возрастает.\n",
    "#5й раздел содержит максимальное число лекций и заданий, однако средняя успеваемость студентов для него самая низкая.\n",
    "#Успеваемость по 4му и 6му разделу, вероятно, можно улучшить, добавив в них качественные лекции, а по 7му разделу - добавив практические задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cae754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
